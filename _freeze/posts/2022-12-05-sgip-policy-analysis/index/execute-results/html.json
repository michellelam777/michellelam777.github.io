{
  "hash": "327fb6ffaabbb28426b1d9bf3ee9a3e8",
  "result": {
    "markdown": "---\ntitle: \"California Battery Rebate Program Analysis\"\ndescription: \"Exploring the effects of income on Self Generation Incentive Program (SGIP) applications\"\nauthor:\n  - name: Michelle Lam\n    affiliation: Masters of Environmental Data Science (MEDS) @ The Bren School (UCSB)\n    affiliation-url: https://ucsb-meds.github.io/\ndate: 2022-12-05\ncategories: [data science, R, energy storage]\ncitation: \n  url: https://michellelam777.github.io/posts/2022-12-05-sgip-policy-analysis/\ndraft: false\nformat:\n  html: \n    code-fold: true\n    code-summary: \"checkout the code\"\n    code-overflow: wrap\n    code-block-bg: \"#e3f3ff\"\npage-layout: article\nimage: battery-day-night.gif\n---\n\n\n### The Question\n\n#### What is the effect of income on SGIP applications?\n\n### Introduction\n\nEnergy storage is poised for rapid growth and will play a major role in the decarbonization of our energy industry. [^1] The California Public Utilities Commission (CPUC) created the Self Generation Incentive Program (SGIP), in part, to provide rebates to people and organizations looking to install energy storage systems. In September of 2019, they introduced additional funding for the \"Equity\" budget and a new funding category, \"Equity Resiliency\". These funding categories aim to help lower-income, medically vulnerable, and at risk for fire communities pay for a battery. [^2] Given that lower socioeconomic communities are shown to experience more frequent Public Safety Power Shutoffs (PSPS), [^3] an energy storage system could be critical to avoiding the adverse effects of a power outage (e.g. food insecurity). There has been a study showing the socioeconomic disparities in residential battery storage adoption, [^4] but there hasn't been targeted analysis on SGIP participation post equity and equity resiliency funding becoming available.\n\n[^1]: Blair, Nate, Chad Augustine, Wesley Cole, et al. 2022. Storage Futures Study: Key Learnings for the Coming Decades. Golden, CO: National Renewable Energy Laboratory. NREL/TP-7A40-81779. https://www.nrel.gov/docs/fy22osti/81779.pdf\n\n[^2]: Auth, CPUC. \"Participating in Self-Generation Incentive Program (SGIP).\" California Public Utilities Commission, 2020, https://www.cpuc.ca.gov/industries-and-topics/electrical-energy/demand-side-management/self-generation-incentive-program/participating-in-self-generation-incentive-program-sgip.\n\n[^3]: Vilgalys, Max. \"Equity and Adaptation to Wildfire Risk: Evidence from California Public Safety Power Shutoffs.\" (2022).\n\n[^4]: David P. Brown, Socioeconomic and demographic disparities in residential battery storage adoption: Evidence from California, Energy Policy, Volume 164, 2022, 112877, ISSN 0301-4215, https://doi.org/10.1016/j.enpol.2022.112877. (https://www.sciencedirect.com/science/article/pii/S0301421522001021)\n\nExamining if there is an effect of income on SGIP applications for 2020, could help inform the effectiveness of the new funding categories and subsequent policy decisions.\n\n### Data\n\n##### SGIP Applications\n\nI downloaded SGIP application data from the California Distributed Energy Statistics site. [^5] Application data is reported on a weekly basis via an excel file. For this analysis, SGIP applications were filtered down to just residential and single family battery applications for 2020. The data was then summarized by zip code to get total count of applications for each zip code. I did notice that the metadata didn't always correctly specify the categorical values in each variable, so there is room for error in categorization.\n\n[^5]: https://www.californiadgstats.ca.gov/downloads/\n\nWhen visualizing SGIP applications for 2020, 43.14% of applications fall under the Equity and Equity Resiliency categories.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#loading the necessary pacakges\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(gt)\nlibrary(tidycensus)\nlibrary(janitor)\nlibrary(lubridate)\nlibrary(modelr)\nlibrary(gridExtra)\nlibrary(car)\n\n#setting file path for root directory\nrootdir <- (\"/Users/michelle/Documents/UCSB Grad School/Courses/eds_222/eds222_final_project\")\ndatadir <-(file.path(rootdir,\"data\"))\n\n#store and set API key to access tidycensus\ncensus_token <- Sys.getenv('CENSUS_KEY')\ncensus_api_key(census_token)\n\n#read in the SGIP data\nsgip <- read_csv(file.path(datadir,\"sgip_weekly_data.csv\")) |> \n  janitor::clean_names()\n\n#filter down to rebates for just residential electrochemcial storage that were not cancelled, format date and zip\nsgip_res_battery <- sgip |> \n  filter(equipment_type == \"Electrochemical Storage\", host_customer_sector %in% c(\"Residential\", \"Single Family\"), budget_classification != \"Cancelled\") |>\n  select(\"city\", \"county\", \"zip\", \"date_received\", \"budget_category\", \"host_customer_sector\") |> \n  mutate(\"date_received\" = str_sub(date_received, 1, 8)) |> \n  mutate(\"date_received\" = as.Date(date_received, format = \"%m/%d/%y\")) |>\n  mutate(\"year_received\" = year(date_received)) |>\n  mutate(\"month_received\" = month(date_received)) |> \n  mutate(\"zip\" = ifelse(\n    str_length(zip) == 10, \n    substring(zip, 1, nchar(zip)-5),\n    zip))\n\n#create sgip dataset filtered for 2020\nsgip_2020 <- sgip_res_battery |> \n  filter(year_received == 2020)\n\n# create dataframe showing count of applications in each zip code for 2020\nsgip_zip_2020 <- sgip_2020 |> \n  group_by(zip) |> \n  summarize(count = n())\n\n#create a summary data frame showing applications by budget category\nsgip_2020_budget <- sgip_2020 |> \n  group_by(budget_category) |> \n  summarize(count = n()) |> \n  mutate(percent = round(((count/sum(count))*100),2), percent_label = paste0(percent, \"%\"))\n\n#plot percent SGIP applications by category\nggplot(sgip_2020_budget, aes(y = budget_category, x = percent)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue3\") +\n  labs(title = \"Percent of SGIP Applications in Each Budget Category (2020)\", y = \"Budget Category\", x = \"Percent of Applications\") + \n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  geom_label(label = sgip_2020_budget$percent_label)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=960}\n:::\n:::\n\n\n##### American Community Survey (ACS)\n\nI accessed American Community Survey (ACS) data containing per capita income and population for each census tract in California through an API and the tidycensus package in R.[^6] ACS data is provided in tabular format and is read in as a data frame. ACS utilizes a stratified sampling approach, using address blocks to create strata.[^7] This could run the risk of the sample not reflecting the population if strata have overlapping characteristics. Additionally, data might not be as available/reliable for rural areas.[^8]\n\n[^6]: https://walker-data.com/tidycensus/\n\n[^7]: Bureau, US Census. \"Design and Methodology Report.\" Census.gov, 14 Dec. 2021, https://www.census.gov/programs-surveys/acs/methodology/design-and-methodology.html.\n\n[^8]: Research and Training Center on Disability in Rural Communities. (2017). Data limitations in the American Community Survey (ACS): The impact on rural disability research. Missoula, MT: The University of Montana Rural Institute for Inclusive Communities.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#access ACS data variables for 2020 year \nv20 <- load_variables(2020, \"acs5\", cache = TRUE)\n\n#read in per capita income data for census tracts in CA\nca_pc_income_tract <- get_acs(geography = \"tract\",\n                            variables = c(percapita_income = \"B19301_001\"),\n                            state = \"CA\",\n                            year = 2020)\n\n#clean and format per capita income data frame\nca_pc_income_tract_clean <- ca_pc_income_tract |> \n  select(c(\"GEOID\", \"NAME\", \"estimate\")) |> \n  rename(percapita_income = \"estimate\")\n\n#read in population data for census tracts in CA\nca_pop_tract <- get_acs(geography = \"tract\",\n                        variables = c(population = \"B01003_001\"),\n                        state = \"CA\",\n                        year = 2020)\n\n#clean and format population data frame \nca_pop_tract_clean <- ca_pop_tract |> \n  select(c(\"GEOID\", \"NAME\", \"estimate\")) |> \n  rename(population = \"estimate\")\n\n#combine per capita income and population data frames\ncombine_census <- cbind(ca_pc_income_tract_clean, ca_pop_tract_clean$population) |> \n  rename(population = \"ca_pop_tract_clean$population\", tract = \"GEOID\")\n```\n:::\n\n\n##### U.S. Department of Housing and Urban Development (HUD)\n\nI downloaded the crosswalk file in the form of a csv from the U.S. HUD site. [^9] The file relates zip codes to census tracts and was utilized to match up application data (zip code level) to per capita income and population data (census tract level).\n\n[^9]: https://www.huduser.gov/portal/datasets/usps_crosswalk.html#data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#read in crosswalk file to use when matching zip codes to census tracts\ncrosswalk <- read_csv(file.path(datadir,\"ZIP_TRACT_122020.csv\")) |> \n  janitor::clean_names()\n```\n:::\n\n\n### Analysis\n\nTo analyze the effect of income on SGIP applications, I utilized the three datasets outlined above to create a data frame showing applications per thousand people and per capita income for each zip code. When aggregating from census tract level to zip code level, I took the median per capita income and summed the populations in each census tract to get income and population variables for each zip code. I used population of each zip code to calculate the applications per thousand people in order to account for the fact that higher income areas have more people and to create a more appropriate scale for interpretation. I did notice that after combining the datasets, there were 1933 NA values for per capita income and 1896 NA values for population out of the 10978 census tracts in the dataset. This could lead to inaccuracies since observations are analyzed on the zip code level and aggregation of the census tract data was performed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#combine sgip_zip_2020 and crosswalk file by zip to get a data frame with sgip applications per census tract\n#because there are multiple census tracts for one zip code, use the res_ratio to allocate what portion of the count of SGIP applications should be allocated to one census tract\nsgip_zip_census <- left_join(sgip_zip_2020, crosswalk, by = \"zip\") |> \n  mutate(\"count_adjusted\" = count*res_ratio) #now we have theoretical count of applications per census tract\n\n#combine sgip_zip_census with acs data by tract\ncombined_all <- left_join(sgip_zip_census, combine_census, by = \"tract\") |> \n  mutate(\"percapita_application\" = count_adjusted/population) |>\n  mutate(\"applications_per_thousand\" = (count_adjusted/population)*1000) |> \n  select(c(-\"oth_ratio\", -\"tot_ratio\", -\"bus_ratio\"))\n\n#take the combined_all data frame and consolidate back to apps per zip (averaging per capita income and summing population of each census tract into zip codes)\ncombined_by_zip <- combined_all |> \n  group_by(zip) |> \n  summarize(applications = mean(count, na.rm = TRUE), percapita_income = median(percapita_income, na.rm = TRUE), population = sum(population, na.rm = TRUE)) |> \n  filter(!is.na(percapita_income)) |> \n  mutate(\"applications_per_1000_people\" = (applications/population)*1000, \"percapita_application\" = applications/population)\n```\n:::\n\n\n##### Regression Models\n\nNext, I ran different regression models to see what would best fit the data. I started with a simple linear regression, but noticed that the median per capita income and the applications per thousand people observations were not normally distributed with a right tail (see supporting figures). Therefore, I ran a linear-log regression and log-log regression. The residuals from these models were not normally distributed so I ran a polynomial regression. The residuals on the polynomial regression were not normal either (see supporting figures), but I concluded that the polynomial regression was best fit since visually the slope doesn't look constant and the coefficients were significant. Here is the equation for the model: $$application_i =\\beta_{0}+\\beta_{1} \\cdot income_i + \\beta_{2} \\cdot income_i^2 + \\varepsilon_i$$\n\nI did notice that there was an outlier in the dataset, but when I removed the outlier and ran the polynomial regression it did not change the significance of the coefficients. Because the outlier didn't drastically change model results and there was no evidence that this data point was and outlier caused by data entry or measurement errors, I left it in.\n\nAs mentioned above, on all the models tested the residuals were not normally distributed with a long right tail. This means that the amount of error in the model is not consistent across the full range of my observed data and the model's ability to accurately predict applications per thousand people at a given median per capita income is low.\n\n##### Hypothesis Testing\n\nI jointly tested the $\\beta_{1}$ and $\\beta_{2}$ coefficients using the linearHypothesis() function from the car package to test for no relationship between median per capita income and applications per thousand people.\n\n$H_0: \\beta_{1} = 0, \\beta_{2} = 0$\n\n$H_A: \\beta_{j}\\neq 0$ for at least one $j = 1,2$\n\n### Results\n\n##### Polynomial Regression\n\nFrom the below outputs of the model, I can see that the coefficient of per capita income is statistically significant at the 0.1% significance level (p-value = 0.0003) and the coefficient of per capita income squared is statistically significant at the 1% significance level (p-value = 0.0088). The R squared and adjusted R squared are really low at 0.022 and 0.02, respectively. This means that 2% of the variability in applications per thousand people is explained by median per capita income. Having a low R squared value and a high significance for the coefficients in the model could mean that there is a statistically significant relationship between applications and income, but the predictive accuracy of the model is low.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#polynomial regression\npoly_model <- lm(applications_per_1000_people ~ percapita_income + I(percapita_income^2), data = combined_by_zip)\n\n#store all the values of the model \nR2_poly_model = summary(poly_model)$r.squared\nR2_poly_adjusted = summary(poly_model)$adj.r.squared\n\nintercept_poly <- summary(poly_model)$coefficients[\"(Intercept)\", \"Estimate\"]\nb1_poly <- summary(poly_model)$coefficients[\"percapita_income\", \"Estimate\"]\nb2_poly <- summary(poly_model)$coefficients[\"I(percapita_income^2)\", \"Estimate\"]\n\nPredictors <- c(\"Intercept\", \"per capita income\", \"(per capita income)^2\")\nEstimate <- signif(summary(poly_model)$coefficients[,\"Estimate\"], digits = 3)\nSE <- signif(summary(poly_model)$coefficients[,\"Std. Error\"], digits = 3)\np <- round(summary(poly_model)$coefficients[,\"Pr(>|t|)\"], 4)\n\npoly_model_summary <- data.frame(Predictors, Estimate, SE, p)\n\n#create table of regression output\ngt_summary <- poly_model_summary |> \n  gt() |> \n  tab_header(\n    title = \"Polynomial Model Output Summary\"\n  ) |> \n  tab_footnote(\n    footnote = \"Observations: 1104\") |> \n  tab_footnote(\n    footnote = paste(\"R^2/R^2 adjusted:\", round(R2_poly_model,3), \"/\", round(R2_poly_adjusted,3))\n  )\ngt_summary\n```\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"gzmjlbnagr\" style=\"overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>html {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#gzmjlbnagr .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#gzmjlbnagr .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#gzmjlbnagr .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#gzmjlbnagr .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#gzmjlbnagr .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#gzmjlbnagr .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#gzmjlbnagr .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#gzmjlbnagr .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#gzmjlbnagr .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#gzmjlbnagr .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#gzmjlbnagr .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#gzmjlbnagr .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#gzmjlbnagr .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#gzmjlbnagr .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#gzmjlbnagr .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#gzmjlbnagr .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#gzmjlbnagr .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#gzmjlbnagr .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#gzmjlbnagr .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#gzmjlbnagr .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#gzmjlbnagr .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#gzmjlbnagr .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#gzmjlbnagr .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#gzmjlbnagr .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#gzmjlbnagr .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#gzmjlbnagr .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#gzmjlbnagr .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#gzmjlbnagr .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#gzmjlbnagr .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-left: 4px;\n  padding-right: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#gzmjlbnagr .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#gzmjlbnagr .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#gzmjlbnagr .gt_left {\n  text-align: left;\n}\n\n#gzmjlbnagr .gt_center {\n  text-align: center;\n}\n\n#gzmjlbnagr .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#gzmjlbnagr .gt_font_normal {\n  font-weight: normal;\n}\n\n#gzmjlbnagr .gt_font_bold {\n  font-weight: bold;\n}\n\n#gzmjlbnagr .gt_font_italic {\n  font-style: italic;\n}\n\n#gzmjlbnagr .gt_super {\n  font-size: 65%;\n}\n\n#gzmjlbnagr .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 75%;\n  vertical-align: 0.4em;\n}\n\n#gzmjlbnagr .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#gzmjlbnagr .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#gzmjlbnagr .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#gzmjlbnagr .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#gzmjlbnagr .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#gzmjlbnagr .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\">\n  <thead class=\"gt_header\">\n    <tr>\n      <td colspan=\"4\" class=\"gt_heading gt_title gt_font_normal gt_bottom_border\" style>Polynomial Model Output Summary</td>\n    </tr>\n    \n  </thead>\n  <thead class=\"gt_col_headings\">\n    <tr>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\">Predictors</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">Estimate</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">SE</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\">p</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td class=\"gt_row gt_left\">Intercept</td>\n<td class=\"gt_row gt_right\">-1.69e-01</td>\n<td class=\"gt_row gt_right\">2.08e-01</td>\n<td class=\"gt_row gt_right\">0.4186</td></tr>\n    <tr><td class=\"gt_row gt_left\">per capita income</td>\n<td class=\"gt_row gt_right\">2.95e-05</td>\n<td class=\"gt_row gt_right\">8.12e-06</td>\n<td class=\"gt_row gt_right\">0.0003</td></tr>\n    <tr><td class=\"gt_row gt_left\">(per capita income)^2</td>\n<td class=\"gt_row gt_right\">-1.80e-10</td>\n<td class=\"gt_row gt_right\">6.85e-11</td>\n<td class=\"gt_row gt_right\">0.0088</td></tr>\n  </tbody>\n  \n  <tfoot class=\"gt_footnotes\">\n    <tr>\n      <td class=\"gt_footnote\" colspan=\"4\"> Observations: 1104</td>\n    </tr>\n    <tr>\n      <td class=\"gt_footnote\" colspan=\"4\"> R^2/R^2 adjusted: 0.022 / 0.02</td>\n    </tr>\n  </tfoot>\n</table>\n</div>\n```\n:::\n:::\n\n\nWhen looking at the below graph and resulting formula, we can conclude that the effect of an increase on median per capita income on applications per thousand people depends on the baseline level of median per capita income.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#plot\nggplot(data = combined_by_zip, aes(x = percapita_income, y = applications_per_1000_people)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", formula = y ~ x + I(x^2), size = 1) +\n  scale_x_continuous(name=\"Median Per Capita Income\", labels = scales::comma) +\n  labs(x = \"Median Per Capita Income\", y = \"Applications Per 1000 People\", title = \"SGIP Applications Per Thousand People and Income Per Capita (2020)\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n$$application_i = -0.169 + 2.95e^{-5}\\cdot income_i -1.80e^{-10}\\cdot income_i^2 + \\varepsilon_i$$\n\n\nTo interpret output from the model, we can look at the difference in predicted applications per thousand people between regions of median per capita income.\n\nWhen moving from a median per capita income of 15,000 to 25,000 (low income), predicted applications per thousand people increases by 0.22. When moving from a median per capita income of 60,000 to 70,000 (middle income), predicted applications per thousand people increases by 0.06. When moving from a median per capita income of 100,000 to 110,000 (high income), predicted applications per thousand people decreases by 0.08.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#create a function out of the polynomial regression\napp_pred_function <- function(income){\n  return(intercept_poly + (b1_poly * income) + (b2_poly * (income^2)))\n}\n\n#predicted applications per 1000 people for per capita income of 15,000 vs. 25,000\npred_15000 <- app_pred_function(income = 15000)\npred_25000 <- app_pred_function(income = 25000)\n\ndiff_pred_low <- pred_25000 - pred_15000\ndiff_pred_low\n\n#predicted applications per 1000 people for per capita income of 60,000 vs. 70,000\npred_60000 <- app_pred_function(income = 60000)\npred_70000 <- app_pred_function(income = 70000)\n\ndiff_pred_mid<- pred_70000 - pred_60000\ndiff_pred_mid\n\n#predicted applications per 1000 people for per capita income of 100,000 vs. 110,000\npred_100000 <- app_pred_function(income = 100000)\npred_110000 <- app_pred_function(income = 110000)\n\ndiff_pred_high <- pred_110000- pred_100000\ndiff_pred_high\n```\n:::\n\n\n##### Hypothesis Testing\n\nThe resulting F-statistic (12.39) and p-value (4.76e-06) from the hypothesis testing indicate that I can reject my null hypothesis that both coefficients are 0 (i.e. there is no relationship between median per capita income and applications per thousand people).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#jointly test if beta1 and beta 2 are 0, test that there is no relationship at all between y and x\nlinearHypothesis(poly_model,c(\"percapita_income = 0\", \"I(percapita_income^2) = 0\"))\n```\n:::\n\n\n### Conclusion and Next Steps\n\nFrom the results of this analysis, I can conclude that income does have an effect on SGIP applications. It is hard to definitely say that the SGIP program is or is not helping lower income communities since the slope of the model increases up until a certain point and then decreases. From previous research mentioned in the introduction, I would have thought the slope of the model would be consistently positive. This would have shown that the SGIP program was being utilized less by low income communities. The model does, however, conclude that the lowest income communities are not utilizing the SGIP program. This can be due to a number of factors including, but not limited to, energy storage systems often being paired with solar, requirements of home ownership, and a lengthy rebate process that are barriers to adoption of this program. Some further analysis that would help determine if the equity and equity resiliency funding is helping low income communities is to compare pre 2020 applications to post 2020 applications to get a sense of the change in program participation among low income communities. Also adding medical vulnerability and wildfire risk as predictors to the model could indicate if those communities are utilizing the program and control for interactions between income and these additional variables.\n\nCheck out the full code in my repo: <https://github.com/michellelam777/eds222_final_project>\n\n### Supporting Figures\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#histogram for per capita income\nggplot(data = combined_by_zip) +\n  geom_histogram(aes(percapita_income), fill = \"skyblue3\") +\n  scale_x_continuous(name=\"Median Per Capita Income\", labels = scales::comma) +\n  labs(title = \"Distribution of Median Per Capita Income (2020)\", y = \"Count\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#histogram for applications per 1000 people\nggplot(data = combined_by_zip) +\n  geom_histogram(aes(applications_per_1000_people), fill = \"skyblue3\") +\n  labs(x = \"SGIP Applictions Per Thousand People\", y = \"Count\", title = \"Distribution of Applications Per Thousand People (2020)\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#get a predicted value for every observation (generate a column of predictions called pred)\n#then use predictions to compute residuals (actual - prediction) -> add column called residuals\npredictions_4 <- combined_by_zip |> \n  add_predictions(poly_model) |> \n  mutate(residuals = applications_per_1000_people - pred)\n\n#test assumption that errors are normally distributed\npoly_residuals_hist <- ggplot(data = predictions_4) +\n  geom_histogram(aes(residuals)) +\n  labs(title = \"Residuals from Polynomial Model\", x = \"(apps ~ income + income^2) residuals\") +\n  theme_minimal()\n\npoly_income_qq <- ggplot(data = predictions_4,\n       aes(sample = residuals)) +\n  geom_qq() +\n  geom_qq_line() +\n  labs(title = \"QQ Plot Polynomial Model Residuals\") +\n  theme_minimal()\n\ngrid.arrange(poly_residuals_hist, poly_income_qq, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-3.png){width=672}\n:::\n:::\n\n\n### References\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}